# Experimenting with Closed and Open Source LLMs

## Introduction

This project explores the capabilities of both closed and open-source Large Language Models (LLMs) through a series of innovative experiments. Inspired by methods demonstrated in two YouTube videos, we delve into prompt engineering, fine-tuning, Retriever-Augmented Generation (RAG), local interpreter usage, function calling, and CPU inference with Llama.cpp. By applying these techniques to new datasets and tasks, we aim to showcase the versatility and potential of LLMs in various applications.

## Table of Contents
- [Introduction](#introduction)
- [Installation](#installation)
- [Usage](#usage)
- [Features](#features)
- [New Datasets and Tasks](#new-datasets-and-tasks)
- [Dependencies](#dependencies)
- [Configuration](#configuration)
- [Documentation](#documentation)
- [Examples](#examples)
- [Troubleshooting](#troubleshooting)
- [Contributors](#contributors)
- [License](#license)
- [Learnings and Organization](#learnings-and-organization)

## Installation

Instructions for setting up the project environment. This should include steps for installing required software, libraries, and any other dependencies.

## Usage

Details on how to run the experiments, including command-line instructions or configurations needed for execution.

## Features

An overview of the project's key features, highlighting the innovative use of LLMs and the specific functionalities explored through the experiments.

## New Datasets and Tasks

Description of the new datasets and tasks selected for this project, including the rationale behind these choices and how they differ from those in the original experiments. For example, using datasets from [huggingface.co/knowrohit07](https://huggingface.co/knowrohit07) for diverse applications.

## Dependencies

A list of all external libraries or frameworks required by the project, with versions and installation instructions.

## Configuration

If applicable, provide details on configuring the project, including any necessary configuration files or environment variables.

## Documentation

Links to external documentation for tools, models, or libraries used in the project.

## Examples

Examples of how to run the experiments, including command-line snippets and expected outcomes.

## Troubleshooting

Guidance for resolving common issues encountered during the setup or execution of the experiments.

## Contributors

Acknowledgment of individuals who contributed to the project.

## License

Information on the project's license, detailing how others may use or contribute to the project.

## Learnings and Organization

A reflective section discussing key learnings, challenges, and how the project was organized. Highlight any significant changes made to the original experiments, including how these alterations demonstrate creativity and innovation in the application of LLM technologies.

---

This README provides a comprehensive overview of our project on experimenting with closed and open-source LLMs. Through this documentation, we aim to share our journey, insights, and contributions to the field of machine learning and language model applications.
